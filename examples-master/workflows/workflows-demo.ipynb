{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflows\n",
    "\n",
    "Complex machine learning applications often require multi-stage pipelines (e.g., data loading, transforming, training, testing, iterating). **Workflows** in Spell allow you to manage these pipelines as a sequence of Spell runs, and are a lightweight alternative to tools like [Airflow](https://airflow.apache.org/) and [Luigi](https://github.com/spotify/luigi) for managing your model training pipelines.\n",
    "\n",
    "Workflows can be launched using either the Spell CLI or the Spell Python API. In this tutorial we demonstrate both approaches by example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understanding workflows\n",
    "\n",
    "Every workflow consists of one *master run* and one more more *worker runs*. The master run is responsible for control flow: that is, determining which worker runs should get executed when, and why. The worker runs then do all of the work required.\n",
    "\n",
    "Our demo workflow consists of three steps:\n",
    "\n",
    "1. downloading the dataset (a Project Gutenberg copy of _War and Peace_) and saving it to disk.\n",
    "2. mounting that text corpus into a run, training the neural network on it, and saving the model to disk.\n",
    "3. mounting the saved model into yet another run, sampling it for an interesting result, and streaming that output to logs.\n",
    "\n",
    "To accomplish this, we will need one one master run and three worker runs, arranged thusly:\n",
    "\n",
    "![](https://i.imgur.com/W5Ugs0S.png)\n",
    "\n",
    "For this simple example we will execute the steps consecutively, conditioning the start of each worker run in the workflow on the success of its predecessor. More complex workflows may require more complicated control flow.\n",
    "\n",
    "While the instance type of the worker runs is configurable, the master run always executes on the basic `cpu` instance type. Try to keep any computationally intensive logic isolated to the workers!\n",
    "\n",
    "## understanding the workflow script\n",
    "\n",
    "In order to execute a workflow, we need to define a workflow script. The **workflow script** is what gets executed on the master run: a Python script using the Spell Python API to define worker jobs and the control flow logic surrounding them.\n",
    "\n",
    "Here is a dead-simple workflow script. Don't worry if you don't understand all of it right away, we'll walk through it step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simple.py\n",
    "import spell.client\n",
    "client = spell.client.from_environment()\n",
    "\n",
    "print(client.active_workflow)\n",
    "\n",
    "r1 = client.runs.new(command=\"echo Hello World! > foo.txt\")\n",
    "r1.wait_status(*client.runs.FINAL)\n",
    "r1.refresh()\n",
    "if r1.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "\n",
    "r2 = client.runs.new(\n",
    "    command=\"cat /mnt/foo.txt\",\n",
    "    attached_resources={f\"runs/{r1.id}/foo.txt\": \"/mnt/foo.txt\"}\n",
    ")\n",
    "r2.wait_status(*client.runs.FINAL)\n",
    "r2.refresh()\n",
    "if r2.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "\n",
    "print(\"Finished workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through this script step-by-step:\n",
    "\n",
    "```python\n",
    "import spell.client\n",
    "client = spell.client.from_environment()\n",
    "```\n",
    "\n",
    "This initializes the client object. If you are not familiar with our Python API, check out the [Python API Reference](http://spell.run/docs/python) to learn more.\n",
    "\n",
    "\n",
    "```python\n",
    "print(client.active_workflow)\n",
    "```\n",
    "\n",
    "You can use this variable to determine which workflow the script is currently executing in. In the case that this script is not being run from inside of a workflow this will be set to `None`.\n",
    "\n",
    "```python\n",
    "r1 = client.runs.new(command=\"echo 'Hello World!' > foo.txt\")\n",
    "```\n",
    "\n",
    "This next block of code executes a new run, one which creates a file containing `Hello World!` on disk. This file automatically gets saved to SpellFS.\n",
    "\n",
    "```python\n",
    "r1.wait_status(*client.runs.FINAL)\n",
    "r1.refresh()\n",
    "if r1.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "```\n",
    "\n",
    "We can only proceed to the next stage of the workflow when the first stage completes successfully. This next bit of code is a control flow block that achieves this.\n",
    "\n",
    "Every run transitions through a sequence of states as part of its execution: `machine_requested`, `running`, `pushing`, and so on. Runs eventually transition to a so-called **final state**: the state that the run is assigned at the end of its execution. There are four different possible final states, the most important of which is `COMPLETE`. A run which terminates in the `COMPLETE` state is one which has successfully run all of its code and pushed all of its outputs to SpellFS.\n",
    "\n",
    "This `wait_status` methods blocks execution until the run API reports that the run has reached a final state. We then `refresh` the information on the run object (this has to be done manually because it requires a network roundtrip) and check if the `r.status` field reports that the run is `COMPLETE`. We only proceed with the rest of the script if it is&mdash;if it is not, e.g. if the run reached a failing final state (`FAILED`, `STOPPED`, or `INTERRUPTED`), we raise an error instead.\n",
    "\n",
    "```python\n",
    "r2 = client.runs.new(\n",
    "    command=\"cat /mnt/foo.txt\",\n",
    "    attached_resources={f\"runs/{r1.id}/foo.txt\": \"/mnt/foo.txt\"}\n",
    ")\n",
    "r2.wait_status(*client.runs.FINAL)\n",
    "r2.refresh()\n",
    "if r2.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "```\n",
    "\n",
    "The next code block creates another Spell run. This time instead of writing `Hello World!` to disk, we mount the `foo.txt` file we created in `r1` into the run. We then `cat` it (print it out to `stdout`), which will cause it to show up in the run logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## executing the workflow script\n",
    "\n",
    "You can execute the workflow script using the Spell CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m✨ Preparing uncommitted changes…\n",
      "\u001b[0mEnumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 12 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 649 bytes | 649.00 KiB/s, done.\n",
      "Total 5 (delta 4), reused 0 (delta 0)\n",
      "To git.spell.run:aleksey/e6cee8710721a8ef6f3d2924713ac7d351c972ca.git\n",
      " * [new branch]      HEAD -> br_9beb42bead69bba7ca10038c6207ac35601c371b\n",
      "💫 Casting workflow #14…\n",
      "\u001b[0m✨ Following workflow at run 350.\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Building… donecode[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m✨ \u001b[0mRun is running\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Machine_Requested… done-- waiting for a CPU machine..[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Saving… done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Pushing… done\n",
      "\u001b[0m🎉 \u001b[0mTotal run time: 36.630201s\n",
      "\u001b[0m🎉 \u001b[0mRun 350 complete\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell workflow \"python simple.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that this workflow executed successfully by checking the run logs of the last worker run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Machine_Requested… done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Building… done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Mounting… done\n",
      "\u001b[0m\u001b[0m✨ \u001b[0mRun is running\n",
      "\u001b[0mHello World!\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Saving… done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Pushing… done\n",
      "\u001b[0m🎉 \u001b[0mTotal run time: 11.525986s\n",
      "\u001b[0m🎉 \u001b[0mRun 352 complete\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell logs 352"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a more complex example\n",
    "\n",
    "As with any run, the code environment in a worker run can be initialized from a GitHub repository using the `--github-url` flag.\n",
    "\n",
    "However, with more complex pipelines it is sometimes useful to make the exact model code used a runtime variable. To support this use case, the Python API additionally supports initializing the code environment from a local `git` repository inside of the master run using the `--repo` flag.\n",
    "\n",
    "The following example demonstrates how this feature works. This workflow downloads a copy of _War and Peace_ from Project Gutenberg in a first run; trains a character-level RNN on this data in a second run; and then samples some text from the model in a third and final run. Note the use of the `commit_label` flag on the `run` command; this tells the run to initialize the code environment using the repository with the label `char-rnn`. It is the responsibility of the user to set this value accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflow.py\n",
    "import spell.client\n",
    "client = spell.client.from_environment()\n",
    "\n",
    "# create the first run to download the dataset (War and Peace, by Leo Tolstoy)\n",
    "# if desired, replace data_url with url to another plain text file to train on\n",
    "data_url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n",
    "r1 = client.runs.new(\n",
    "    command=\"wget -O input.txt {}\".format(data_url)\n",
    ")\n",
    "print(\"waiting for run {} to complete\".format(r1.id))\n",
    "r1.wait_status(*client.runs.FINAL)\n",
    "r1.refresh()\n",
    "if r1.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r1.id}\")\n",
    "\n",
    "# create the second run to train char-RNN on the dataset\n",
    "data_dir = \"/data\"\n",
    "r2 = client.runs.new(\n",
    "    machine_type=\"t4\",\n",
    "    command=\"python train.py --data_dir={}\".format(data_dir),\n",
    "    attached_resources={\n",
    "        \"runs/{}/input.txt\".format(r1.id): \"{}/input.txt\".format(data_dir)\n",
    "    },\n",
    "    commit_label=\"char-rnn\",\n",
    ")\n",
    "print(\"waiting for run {} to complete\".format(r2.id))\n",
    "\n",
    "r2.wait_status(*client.runs.FINAL)\n",
    "r2.refresh()\n",
    "if r2.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r2.id}\")\n",
    "\n",
    "# create the third run that samples the model to generate some text\n",
    "r3 = client.runs.new(\n",
    "    machine_type=\"t4\",\n",
    "    command=\"python sample.py\",\n",
    "    attached_resources={\"runs/{}/save\".format(r3.id): \"save\"},\n",
    "    commit_label=\"char-rnn\",\n",
    ")\n",
    "print(\"waiting for run {} to complete\".format(r3.id))\n",
    "\n",
    "r3.wait_status(*client.runs.FINAL)\n",
    "r3.refresh()\n",
    "if r3.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r3.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this workflow we will need the following model code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'char-rnn-tensorflow'...\n",
      "remote: Enumerating objects: 404, done.\u001b[K\n",
      "remote: Total 404 (delta 0), reused 0 (delta 0), pack-reused 404\u001b[K\n",
      "Receiving objects: 100% (404/404), 508.45 KiB | 1.19 MiB/s, done.\n",
      "Resolving deltas: 100% (238/238), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sherjilozair/char-rnn-tensorflow.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, when we execute this workflow, we parameterize the repo label using the `--repo` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m✨ Syncing repo char-rnn-tensorflow/.\n",
      "\u001b[0mEverything up-to-date\n",
      "✨ Preparing uncommitted changes…\n",
      "\u001b[0mEnumerating objects: 11, done.\n",
      "Counting objects: 100% (11/11), done.\n",
      "Delta compression using up to 12 threads\n",
      "Compressing objects: 100% (6/6), done.\n",
      "Writing objects: 100% (6/6), 2.41 KiB | 2.41 MiB/s, done.\n",
      "Total 6 (delta 5), reused 0 (delta 0)\n",
      "To git.spell.run:aleksey/e6cee8710721a8ef6f3d2924713ac7d351c972ca.git\n",
      " * [new branch]      HEAD -> br_b1dfb5675ed1f875f975838304d4cfc546e207db\n",
      "💫 Casting workflow #15…\n",
      "\u001b[0m✨ Following workflow at run 353.\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[1m\u001b[36m⭐\u001b[0m Building… Retrieving codee\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m^C\n",
      "\u001b[0m\n",
      "\u001b[0m✨ Use 'spell logs 353' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell workflow \\\n",
    "    --repo char-rnn=char-rnn-tensorflow/ \\\n",
    "    \"python workflow.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the sample output we generated using our finished model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-05 15:35:54.000600: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      " of Moscupe, who foll and since hoer. We are and still turned\n",
      "merely as the corner that argument in lors for so a quality that.\n",
      "Welllaration wehe return, raisements of\n",
      "such a Frenchmen inspecting for them tallow me with the same correct actions,\n",
      "fellows and well—or watching, in animation, gay others.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER XVIII\n",
      " Yasova and givein offers, and man—do not restraining the woode, they pause they seemed to many apply as he left cordier in\n",
      "which Now did not be week wiplocking France \n",
      "✨ Run is saving\n",
      "✨ Run is pushing\n",
      "Saving build environment for future runs\n",
      "🎉 Total run time: 22.285643s\n",
      "🎉 Run 338 complete\n",
      "Scanning for modified or new files from the run\n"
     ]
    }
   ],
   "source": [
    "!spell logs 338 | tail -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for just an one hour of model training time on a single book!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## further reference\n",
    "\n",
    "The `with-metrics` and `video-generation-workflow` folders in this repository contain even more code samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
